[TOC]



## HashMap 为什么是线程不安全的？

###  HashMap 中 put 方法的源码：

```java
public V put(K key, V value) {
    if (key == null)
        return putForNullKey(value);
    int hash = hash(key.hashCode());
    int i = indexFor(hash, table.length);
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        Object k;
        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    } 
    //modCount++ 是一个复合操作
    modCount++;
    addEntry(hash, key, value, i);
    return null;
}
```

put方法执行步骤：

- 第一个步骤是读取；
- 第二个步骤是增加；
- 第三个步骤是保存。

### HashMap 的线程问题：

#### 1.modCount 计算错：

modCount：修改次数，如果两个线程以上访问put方法可能导致modCount 的值计算错。

#### 2.扩容期间取出的值不准确：

扩容期间获取值有可能获取的是null

#### 3.同时put碰撞导致数据丢失：

多个线程同时put，恰好key是一样的，发生了碰撞，这样最终只会保留一个数据，丢失一个数据。

#### 4.可见性问题无法保证：

HashMap做不到可见性，如果线程 1 给某个 key 放入了一个新值，那么线程 2 在获取对应的 key 的值的时候，它的可见性是无法保证的，也就是说线程 2 可能可以看到这一次的更改，但也有可能看不到。所以从可见性的角度出发，HashMap 同样是线程非安全的。

#### 5.死循环造成 CPU 100%：

扩容时，多线程引发死循环问题。这种循环是链表的循环，相当于 A 节点指向 B 节点，B 节点又指回到 A 节点，在获取该 key 所对应的 value 的时候，便会在遍历链表的时候发生永远无法遍历结束的情况，也就发生 CPU 100% 的情况。（CPU100%的问题主要是在jdk1.8之前的头插法，在jdk1.8已经修改为尾插法，但是其他原因仍然会导致CPU100%问题，所以多线程情况下不推荐使用HashMap）



## ConcurrentHashMap 在 Java7 和 8 有何不同？

在 Java 8 中，对于 ConcurrentHashMap 这个常用的工具类进行了很大的升级，对比之前 Java 7 版本在诸多方面都进行了调整和变化。

### java7的ConcurrentHashMap ：

![img](https://s0.lgstatic.com/i/image3/M01/61/20/CgpOIF4b3hKAfFsTAAG5MQvpc-w836.png)

在 ConcurrentHashMap 内部进行了 Segment 分段，<span style="color:red">Segment 之间是独立上锁的，互不影响，</span>相比于之前的 Hashtable 每次操作都需要把整个对象锁住而言，大大提高了并发效率。因为它的锁与锁之间是独立的，而不是整个对象只有一把锁。

<span style="color:red">每个 Segment 的底层数据结构与 HashMap 类似</span>,仍然是数组和链表组成的拉链法结构。默认有 0~15 共 16 个 Segment，所以最多可以同时支持 16 个线程并发操作（操作分别分布在不同的 Segment 上）。16 这个默认值可以在初始化的时候设置为其他值，<span style="color:red">但是一旦确认初始化以后，是不可以扩容的。</span>

### java8的ConcurrentHashMap ：

![img](https://s0.lgstatic.com/i/image3/M01/61/21/Cgq2xl4b3oCAAFxPAAGZw5NzqtE099.png)

java8的ConcurrentHashMap数据结构相当于HashMap，但是和HashMap区别的是链表长度大于某一个阈值（默认为 8），链表会转化为红黑树。

红黑树的一些其他特点：

- 每个节点要么是红色，要么是黑色，但根节点永远是黑色的。
- 红色节点不能连续，也就是说，红色节点的子和父都不能是红色的。
- 从任一节点到其每个叶子节点的路径都包含相同数量的黑色节点。
- 红黑树遍历的时间复杂度是 O(log(n))，链表遍历的时间复杂度是 O(n)。



### java8的ConcurrentHashMap内部存储结构 Node：

```java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val; //把 value 用 volatile 修饰,保证可见性
    volatile Node<K,V> next;//指向下一个节点的 next 指针,方便产生链表结构。
    ...
}
```

### java8的ConcurrentHashMap的put方法：

```java
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) {
        throw new NullPointerException();
    }
    //计算 hash 值
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K, V>[] tab = table; ; ) {
        Node<K, V> f;
        int n, i, fh;
        //如果数组是空的，就进行初始化
        if (tab == null || (n = tab.length) == 0) {
            tab = initTable();
        }
        // 找该 hash 值对应的数组下标
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            //如果该位置是空的，就用 CAS 的方式放入新值
            if (casTabAt(tab, i, null,
                    new Node<K, V>(hash, key, value, null))) {
                break;
            }
        }
        //hash值等于 MOVED 代表在扩容
        else if ((fh = f.hash) == MOVED) {
            tab = helpTransfer(tab, f);
        }
        //槽点上是有值的情况
        else {
            V oldVal = null;
            //用 synchronized 锁住当前槽点，保证并发安全
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    //如果是链表的形式
                    if (fh >= 0) {
                        binCount = 1;
                        //遍历链表
                        for (Node<K, V> e = f; ; ++binCount) {
                            K ek;
                            //如果发现该 key 已存在，就判断是否需要进行覆盖，然后返回
                            if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                            (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent) {
                                    e.val = value;
                                }
                                break;
                            }
                            Node<K, V> pred = e;
                            //到了链表的尾部也没有发现该 key，说明之前不存在，就把新值添加到链表的最后
                            if ((e = e.next) == null) {
                                pred.next = new Node<K, V>(hash, key,
                                        value, null);
                                break;
                            }
                        }
                    }
                    //如果是红黑树的形式
                    else if (f instanceof TreeBin) {
                        Node<K, V> p;
                        binCount = 2;
                        //调用 putTreeVal 方法往红黑树里增加数据
                        if ((p = ((TreeBin<K, V>) f).putTreeVal(hash, key,
                                value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent) {
                                p.val = value;
                            }
                        }
                    }
                }
            }
            if (binCount != 0) {
                //检查是否满足条件并把链表转换为红黑树的形式，默认的 TREEIFY_THRESHOLD 阈值是 8
                if (binCount >= TREEIFY_THRESHOLD) {
                    treeifyBin(tab, i);
                }
                //putVal 的返回是添加前的旧值，所以返回 oldVal
                if (oldVal != null) {
                    return oldVal;
                }
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
```

通过以上的源码分析，我们对于 putVal 方法有了详细的认识，可以看出，方法中会逐步根据当前槽点是未初始化、空、扩容、链表、红黑树等不同情况做出不同的处理。

### get 方法源码分析：

```java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    //计算 hash 值
    int h = spread(key.hashCode());
    //如果整个数组是空的，或者当前槽点的数据是空的，说明 key 对应的 value 不存在，直接返回 null
    if ((tab = table) != null && (n = tab.length) > 0 &&
            (e = tabAt(tab, (n - 1) & h)) != null) {
        //判断头结点是否就是我们需要的节点，如果是则直接返回
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        //如果头结点 hash 值小于 0，说明是红黑树或者正在扩容，就用对应的 find 方法来查找
        else if (eh < 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        //遍历链表来查找
        while ((e = e.next) != null) {
            if (e.hash == h &&
                    ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
```

总结一下 get 的过程：

- 计算 Hash 值，并由此值找到对应的槽点；
- 如果数组是空的或者该位置为 null，那么直接返回 null 就可以了；
- 如果该位置处的节点刚好就是我们需要的，直接返回该节点的值；
- 如果该位置节点是红黑树或者正在扩容，就用 find 方法继续查找；
- 否则那就是链表，就进行遍历链表查找。

### 对比Java7 和Java8 的异同和优缺点：

#### 数据结构：

Java 7 采用 Segment 分段锁来实现，而 Java 8 中的 ConcurrentHashMap 使用数组 + 链表 + 红黑树，在这一点上它们的差别非常大。

#### 并发度：

Java 7 中，每个 Segment 独立加锁，最大并发个数就是 Segment 的个数，默认是 16。

 Java 8 中，锁粒度更细，理想情况下 table 数组元素的个数（也就是数组长度）就是其支持并发的最大个数，并发度比之前有提高。

#### 保证并发安全的原理：

Java 7 采用 Segment 分段锁来保证安全，而 Segment 是继承自 ReentrantLock。

Java 8 中放弃了 Segment 的设计，<span style="color:red">采用 Node + CAS + synchronized 保证线程安全。</span>

#### 遇到 Hash 碰撞：

Java 7 在 Hash 冲突时，会使用拉链法，也就是链表的形式。

Java 8 先使用拉链法，在链表长度超过一定阈值时，将链表转换为红黑树，来提高查找效率。

#### 查询时间复杂度：

Java 7 遍历链表的时间复杂度是 O(n)，n 为链表长度。

Java 8 如果变成遍历红黑树，那么时间复杂度降低为 O(log(n))，n 为树的节点个数。



## 为什么 Map 桶中超过 8 个才转为红黑树？

​	因为单个 TreeNode 需要占用的空间大约是普通 Node 的两倍，所以只有当包含足够多的 Nodes 时才会转成 TreeNodes，而是否足够多就是由 TREEIFY_THRESHOLD 的值决定的。而当桶中节点数由于移除或者 resize 变少后，又会变回普通的链表的形式，以便节省空间。【如果hashCode 分布良好（算法设计合理）的话，当长度为 8 的时候，概率仅为 0.00000006，这是一个小于千万分之一的概率，通常我们的 Map 里面是不会存储这么多的数据的，所以通常情况下，并不会发生从链表向红黑树的转换。】

​	事实上，链表长度超过 8 就转为红黑树的设计，更多的是为了防止用户自己实现了不好的哈希算法时导致链表过长，从而导致查询效率低，而此时转为红黑树更多的是一种保底策略，用来保证极端情况下查询的效率。

​	所以开发过程中如果发现 HashMap 或是 ConcurrentHashMap 内部出现了红黑树的结构，说明哈希算法【hashCode（）】出了问题，需改进。

<span style="color:red">HashMap 也有红黑树？？？</span>



## ConcurrentHashMap 和 Hashtable 的区别？

ConcurrentHashMap 与 Hashtable都是线程安全的。

#### 出现版本不同：

Hashtable 在JDK1.0 就存在了， JDK1.2 版本中实现了 Map 接口，成为了集合框架的一员。

 ConcurrentHashMap 则是在 JDK1.5 中才出现的，也正是因为它们出现的年代不同，而后出现的往往是对前面出现的类的优化，所以它们在实现方式以及性能上，也存在着较大的不同。

#### 实现线程安全的方式不同：

- Hashtable 实现并发安全的原理是通过 synchronized 关键字实现线程安全：

举例：

```java
public synchronized void clear() {
    Entry<?,?> tab[] = table;
    modCount++;
    for (int index = tab.length; --index >= 0; )
        tab[index] = null;
    count = 0;
}
```

可以看出这个 clear() 方法是被 synchronized 关键字所修饰的，同理其他的方法例如 put、get、size 等，也同样是被 synchronized 关键字修饰的。之所以 Hashtable 是线程安全的，是因为几乎每个方法都被 synchronized 关键字所修饰了，这也就保证了线程安全。

- ConcurrentHashMap实现线程安全的原理是利用了 CAS + synchronized + Node 节点的方式，这和 Hashtable 的完全利用 synchronized 的方式有很大的不同。



#### 性能不同：

多线程情况下，Hashtable 的性能很差，，因为每一次修改都需要锁住整个对象，而其他线程在此期间是不能操作的。不仅如此，还会带来额外的上下文切换等开销，<span style="color:red">所以此时它的吞吐量甚至还不如单线程的情况。</span>

而在 ConcurrentHashMap 中，就算上锁也仅仅会对一部分上锁而不是全部都上锁，所以多线程中的吞吐量通常都会大于单线程的情况，也就是说，在并发效率上，ConcurrentHashMap 比 Hashtable 提高了很多

#### 迭代时修改的不同:

Hashtable在迭代时修改会抛出ConcurrentModificationException 异常，ConcurrentHashMap 在迭代时是可以修改的。

**总结：**Hashtable 已经不再推荐使用。



## CopyOnWriteArrayList和Vector 的区别？

#### Vector 介绍：

​	Vector 内部是使用 synchronized 来保证线程安全的，并且锁的粒度比较大，都是方法级别的锁，在并发量高的时候，很容易发生竞争，并发效率相对比较低。在这一点上，Vector 和 Hashtable 很类似。

​	并且，前面这几种 List 在迭代期间不允许编辑，如果在迭代期间进行添加或删除元素等操作，则会抛出 ConcurrentModificationException 异常，这样的特点也在很多情况下给使用者带来了麻烦。

#### CopyOnWriteArrayList介绍：

​	JDK1.5 开始，Java 并发包里提供了使用 CopyOnWrite 机制实现的并发容器，CopyOnWriteArrayList 作为主要的并发 List，CopyOnWrite 的并发集合还包括 CopyOnWriteArraySet，其底层正是利用 CopyOnWriteArrayList 实现的。

- ##### CopyOnWriteArrayList的适用场景：

  适合读多写少的场景。

#### CopyOnWrite思想：

​	当容器需要修改时，不直接修改当前容器，而是先将当前容器进行 Copy，复制出一个新的容器，然后修改新的容器，**完成修改之后，再将原容器的引用指向新的容器**。这样就完成了整个修改过程，读取也不会因为修改受影响。

​	CopyOnWrite读不需要加锁，<span style="color:red">CopyOnWriteArrayList迭代期间允许修改集合内容，</span>ArrayList 在迭代期间如果修改集合的内容，会抛出 ConcurrentModificationException 异常。

如下代码，CopyOnWriteArrayList能正常输出，将CopyOnWriteArrayList改为ArrayList 运行list.add(4);会报错

```java
public class CopyOnWriteArrayListDemo {
    public static void main(String[] args) {
        CopyOnWriteArrayList<Integer> list = new CopyOnWriteArrayList<>(new Integer[]{1, 2, 3});
        System.out.println(list); //[1, 2, 3]
        //Get iterator 1
        Iterator<Integer> itr1 = list.iterator();

        //Add one element and verify list is updated
        list.add(4);
        System.out.println(list); //[1, 2, 3, 4]
 
        //Get iterator 2
        Iterator<Integer> itr2 = list.iterator();
        System.out.println("====Verify Iterator 1 content====");
        itr1.forEachRemaining(System.out::println); //1,2,3
        System.out.println("====Verify Iterator 2 content====");
        itr2.forEachRemaining(System.out::println); //1,2,3,4
    }
}
```

#### CopyOnWriteArrayList缺点：

- 内存占用问题

  因为 CopyOnWrite 的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，这一点会占用额外的内存空间。

- 在元素较多或者复杂的情况下，复制的开销很大

  复制过程不仅会占用双倍内存，还需要消耗 CPU 等资源，会降低整体性能。

- 数据一致性问题

  由于 CopyOnWrite 容器的修改是先修改副本，所以这次修改对于其他线程来说，并不是实时能看到的，只有在修改完之后才能体现出来。如果你希望写入的的数据马上能被其他线程看到，CopyOnWrite 容器是不适用的。

#### CopyOnWriteArrayList源码分析：

-  **CopyOnWriteArrayList添加元素方法add（）：**

```java
public boolean add(E e) {
    // 加锁
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
 
        // 得到原数组的长度和元素
        Object[] elements = getArray();
        int len = elements.length;
 
        // 复制出一个新数组
        Object[] newElements = Arrays.copyOf(elements, len + 1);
 
        // 添加时，将新元素添加到新数组中
        newElements[len] = e;
 
        // 将volatile Object[] array 的指向替换成新数组
        setArray(newElements);
        return true;
    } finally {
        lock.unlock();
    }
}
```

添加过程加锁，添加的过程和之前CopyOnWrite思想是一致的。

- **获取元素get（）：**

```java
public E get(int index) {
    return get(getArray(), index);
}
final Object[] getArray() {
    return array;
}
private E get(Object[] a, int index) {
    return (E) a[index];
}
```

可以看出，get 相关的操作没有加锁，保证了读取操作的高速。

- **迭代器COWIterator 类**

这个迭代器有两个重要的属性，分别是 Object[] snapshot 和 int cursor。其中 snapshot 代表数组的快照，也就是创建迭代器那个时刻的数组情况，而 cursor 则是迭代器的游标。迭代器的构造方法如下：

```java
private COWIterator(Object[] elements, int initialCursor) {
    cursor = initialCursor;
    snapshot = elements;
}
```

可以看出，迭代器在被构建的时候，会把当时的 elements 赋值给 snapshot，而之后的迭代器所有的操作都基于 snapshot 数组进行的，比如：

```java
public E next() {
    if (! hasNext())
        throw new NoSuchElementException();
    return (E) snapshot[cursor++];
}
```

在 next 方法中可以看到，返回的内容是 snapshot 对象，所以，后续就算原数组被修改，这个 snapshot 既不会感知到，也不会受影响，执行迭代操作不需要加锁，也不会因此抛出异常。迭代器返回的结果，和创建迭代器的时候的内容一致。